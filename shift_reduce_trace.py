#!/usr/bin/env python3
"""
ØªØ­Ù„ÛŒÙ„ Ø¯Ø³ØªÛŒ Shift-Reduce Parse - Ù†Ø³Ø®Ù‡ ØªØµØ­ÛŒØ­ Ø´Ø¯Ù‡
Ù†Ù…Ø§ÛŒØ´ Ù…Ø±Ø­Ù„Ù‡ Ø¨Ù‡ Ù…Ø±Ø­Ù„Ù‡ Ù¾Ø§Ø±Ø³ÛŒÙ†Ú¯ Ø¨Ø±Ø§ÛŒ Ø¯Ø³ØªÙˆØ±Ø§Øª Cache

Ù¾Ø±ÙˆÚ˜Ù‡ Ú©Ø§Ù…Ù¾Ø§ÛŒÙ„Ø± - Ú¯Ø±ÙˆÙ‡ 15
Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡ Ø´Ù‡ÛŒØ¯ Ø¨Ø§Ù‡Ù†Ø± Ú©Ø±Ù…Ø§Ù†
Ù†Ø³Ø®Ù‡ Ù†Ù‡Ø§ÛŒÛŒ - Ú˜Ø§Ù†ÙˆÛŒÙ‡ 2026
"""

from cache_lexer import build_lexer
from lr_tables import LR_PARSING_TABLE, GRAMMAR_RULES


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ú©Ù„Ø§Ø³ Ø§ØµÙ„ÛŒ Ø¨Ø±Ø§ÛŒ Trace Ø¯ÛŒÙ†Ø§Ù…ÛŒÚ©
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class ShiftReduceTracer:
    """ØªØ­Ù„ÛŒÙ„â€ŒÚ¯Ø± Ú¯Ø§Ù…â€ŒØ¨Ù‡â€ŒÚ¯Ø§Ù… Shift-Reduce"""

    def __init__(self):
        # Ø³Ø§Ø®Øª lexer
        self.lexer = build_lexer()
        self.steps = []
        self.step_counter = 0

    def tokenize(self, instruction_text):
        """
        ØªÙˆÚ©Ù†Ø§ÛŒØ² Ú©Ø±Ø¯Ù† ÛŒÚ© Ø¯Ø³ØªÙˆØ±

        Args:
            instruction_text (str): Ø¯Ø³ØªÙˆØ± ÙˆØ±ÙˆØ¯ÛŒ

        Returns:
            list: Ù„ÛŒØ³Øª ØªÙˆÚ©Ù†â€ŒÙ‡Ø§ Ø¨Ù‡ ØµÙˆØ±Øª (type, value)
        """
        self.lexer.input(instruction_text)
        tokens = []

        while True:
            tok = self.lexer.token()
            if not tok:
                break
            tokens.append((tok.type, tok.value))

        return tokens

    def trace(self, instruction_text):
        """
        ØªØ­Ù„ÛŒÙ„ Ú¯Ø§Ù…â€ŒØ¨Ù‡â€ŒÚ¯Ø§Ù… ÛŒÚ© Ø¯Ø³ØªÙˆØ±

        Args:
            instruction_text (str): Ø¯Ø³ØªÙˆØ± ÙˆØ±ÙˆØ¯ÛŒ

        Returns:
            list: Ù„ÛŒØ³Øª Ù…Ø±Ø§Ø­Ù„ Ù¾Ø§Ø±Ø³ÛŒÙ†Ú¯
        """
        self.steps = []
        self.step_counter = 0

        try:
            # Tokenize
            tokens = self.tokenize(instruction_text)

            if not tokens:
                return [{'error': 'ØªÙˆÚ©Ù†â€ŒØ³Ø§Ø²ÛŒ Ù†Ø§Ù…ÙˆÙÙ‚ Ø¨ÙˆØ¯'}]

            # Add end marker
            tokens.append(('$', '$'))

            # Initialize
            stack = [0]  # State stack
            symbol_stack = ['$']  # Symbol stack for display
            token_index = 0

            # Format initial input - âœ… ØªØµØ­ÛŒØ­ Ø´Ø¯Ù‡: ØªØ¨Ø¯ÛŒÙ„ Ù‡Ù…Ù‡ Ø¨Ù‡ string
            input_str = ' '.join([str(t[1]) for t in tokens])

            self._add_step(stack, symbol_stack, tokens, token_index,
                           "Ø´Ø±ÙˆØ¹ Ù¾Ø§Ø±Ø³ÛŒÙ†Ú¯", "")

            while True:
                current_state = stack[-1]
                current_token_type, current_token_value = tokens[token_index]

                # Get action from table
                action = LR_PARSING_TABLE.get(current_state, {}).get(current_token_type)

                if not action:
                    self._add_step(stack, symbol_stack, tokens, token_index,
                                   f"âŒ Ø®Ø·Ø§: Action ØªØ¹Ø±ÛŒÙ Ù†Ø´Ø¯Ù‡",
                                   f"State={current_state}, Token={current_token_type}")
                    break

                # SHIFT
                if isinstance(action, str) and action.startswith('s'):
                    next_state = int(action[1:])
                    stack.append(next_state)
                    # âœ… ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ string Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´
                    symbol_stack.append(str(current_token_value))
                    token_index += 1

                    self._add_step(stack, symbol_stack, tokens, token_index,
                                   f"Shift",
                                   f"Ø§Ù†ØªÙ‚Ø§Ù„ {current_token_type} â†’ State {next_state}")

                # REDUCE
                elif isinstance(action, str) and action.startswith('r'):
                    rule_num = int(action[1:])
                    rule = GRAMMAR_RULES[rule_num]

                    # Parse rule: "LHS -> RHS"
                    lhs, rhs = rule.split(' -> ')
                    rhs_symbols = rhs.split() if rhs != 'Îµ' else []

                    # Pop from stack
                    pop_count = len(rhs_symbols)
                    if pop_count > 0:
                        for _ in range(pop_count):
                            stack.pop()
                            symbol_stack.pop()

                    # Get goto state
                    goto_state = stack[-1]
                    goto_action = LR_PARSING_TABLE.get(goto_state, {}).get(lhs)

                    # âœ… ØªØµØ­ÛŒØ­: Ø¨Ø±Ø±Ø³ÛŒ Ù†ÙˆØ¹ int (Ù†Ù‡ string!)
                    if goto_action is not None and isinstance(goto_action, int):
                        next_state = goto_action
                        stack.append(next_state)
                        symbol_stack.append(lhs)

                        self._add_step(stack, symbol_stack, tokens, token_index,
                                       f"Reduce",
                                       f"R{rule_num}: {rule}")
                    else:
                        self._add_step(stack, symbol_stack, tokens, token_index,
                                       f"âŒ Ø®Ø·Ø§",
                                       f"Goto Ù†Ø§Ù…Ø¹ØªØ¨Ø± ({goto_state}, {lhs})")
                        break

                # ACCEPT
                elif action == 'acc':
                    self._add_step(stack, symbol_stack, tokens, token_index,
                                   "Accept",
                                   "âœ… Ù¾Ø°ÛŒØ±Ø´")
                    break

                else:
                    self._add_step(stack, symbol_stack, tokens, token_index,
                                   f"âŒ Ø®Ø·Ø§",
                                   f"Action Ù†Ø§Ù…Ø¹ØªØ¨Ø±: {action}")
                    break

            return self.steps

        except Exception as e:
            import traceback
            traceback.print_exc()
            return [{'error': f'Ø®Ø·Ø§ Ø¯Ø± ØªØ­Ù„ÛŒÙ„: {str(e)}'}]

    def _add_step(self, stack, symbol_stack, tokens, token_index, action, rule=''):
        """Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† ÛŒÚ© Ù…Ø±Ø­Ù„Ù‡ Ø¨Ù‡ trace"""
        self.step_counter += 1

        # Format stack display
        stack_display = ' '.join(str(s) for s in symbol_stack)

        # Format remaining input - âœ… ØªØµØ­ÛŒØ­ Ø´Ø¯Ù‡: ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ string
        remaining = []
        for i in range(token_index, len(tokens)):
            token_type, token_val = tokens[i]
            # ØªØ¨Ø¯ÛŒÙ„ Ù‡Ù…Ù‡ Ù…Ù‚Ø§Ø¯ÛŒØ± Ø¨Ù‡ string
            remaining.append(str(token_val) if token_val else token_type)
        input_str = ' '.join(remaining)

        step = {
            'step': self.step_counter,
            'stack': stack_display,
            'input': input_str,
            'action': action,
            'rule': rule
        }

        self.steps.append(step)

    def print_trace(self, steps):
        """Ú†Ø§Ù¾ trace Ø¨Ù‡ ØµÙˆØ±Øª Ø¬Ø¯ÙˆÙ„"""

        if not steps:
            print("âŒ Ù‡ÛŒÚ† Ù…Ø±Ø­Ù„Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯")
            return

        # Check for error
        if 'error' in steps[0]:
            print(f"\nâŒ {steps[0]['error']}\n")
            return

        print("\n" + "â”€" * 100)

        # Header
        header = f"{'Ù…Ø±Ø­Ù„Ù‡':<8} | {'Ù¾Ø´ØªÙ‡ (Stack)':<30} | {'ÙˆØ±ÙˆØ¯ÛŒ Ø¨Ø§Ù‚ÛŒâ€ŒÙ…Ø§Ù†Ø¯Ù‡':<25} | {'Ø¹Ù…Ù„ÛŒØ§Øª':<15} | {'Ù‚Ø§Ù†ÙˆÙ†/ØªÙˆØ¶ÛŒØ­':<20}"
        print(header)
        print("â”€" * 100)

        # Rows
        for step in steps:
            step_num = step.get('step', '')
            stack = step.get('stack', '')[:28]
            input_str = step.get('input', '')[:23]
            action = step.get('action', '')[:13]
            rule = step.get('rule', '')[:18]

            row = f"{step_num:<8} | {stack:<30} | {input_str:<25} | {action:<15} | {rule:<20}"
            print(row)

        print("â”€" * 100)

        # Summary
        final_step = steps[-1]
        if 'âœ…' in final_step.get('rule', '') or 'Accept' in final_step.get('action', ''):
            print("âœ… Ù¾Ø§Ø±Ø³ Ù…ÙˆÙÙ‚ - Ø¯Ø³ØªÙˆØ± Ù…Ø¹ØªØ¨Ø± Ø§Ø³Øª\n")
        else:
            print("âŒ Ù¾Ø§Ø±Ø³ Ù†Ø§Ù…ÙˆÙÙ‚ - Ø¯Ø³ØªÙˆØ± Ù†Ø§Ù…Ø¹ØªØ¨Ø± Ø§Ø³Øª\n")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ØªØ§Ø¨Ø¹ Ø§ØµÙ„ÛŒ Ø¨Ø±Ø§ÛŒ main.py - trace_shift_reduce (Ù†Ø§Ù… ØªØµØ­ÛŒØ­ Ø´Ø¯Ù‡!)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def trace_shift_reduce(instruction):
    """
    ØªØ­Ù„ÛŒÙ„ Shift-Reduce ÛŒÚ© Ø¯Ø³ØªÙˆØ± (ÙØ±Ø§Ø®ÙˆØ§Ù†ÛŒ Ø§Ø² main.py)

    âœ… Ù†Ø§Ù… ØªØ§Ø¨Ø¹ ØªØµØ­ÛŒØ­ Ø´Ø¯Ù‡: trace_shift_reduce

    Args:
        instruction (str): Ø¯Ø³ØªÙˆØ± ÙˆØ±ÙˆØ¯ÛŒ
    """

    print("\n" + "â•" * 100)
    print(f"ğŸ“‹ Ø¯Ø³ØªÙˆØ± ÙˆØ±ÙˆØ¯ÛŒ: {instruction}")
    print("â•" * 100)

    tracer = ShiftReduceTracer()
    steps = tracer.trace(instruction)
    tracer.print_trace(steps)

    # Show grammar rules used
    if steps and 'error' not in steps[0]:
        print("â”€" * 100)
        print("ğŸ“œ Ù‚ÙˆØ§Ù†ÛŒÙ† Ú¯Ø±Ø§Ù…Ø± Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø´Ø¯Ù‡:")
        print("â”€" * 100)

        rules_used = []
        for step in steps:
            rule_text = step.get('rule', '')
            if rule_text.startswith('R') and ':' in rule_text:
                rule_line = rule_text.split(':')[0].strip()
                if rule_line not in rules_used:
                    rules_used.append(rule_line)

        for rule_line in rules_used:
            print(f"  â€¢ {rule_line}")

    print("â•" * 100 + "\n")


# Ø¨Ø±Ø§ÛŒ Ø³Ø§Ø²Ú¯Ø§Ø±ÛŒ Ø¨Ø§ Ú©Ø¯ Ù‚Ø¯ÛŒÙ…ÛŒ
analyze_shift_reduce = trace_shift_reduce


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ØªÙˆØ§Ø¨Ø¹ Ú©Ù…Ú©ÛŒ
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def print_header(title):
    print("\n" + "â•" * 100)
    print(f" {title}")
    print("â•" * 100)


def print_trace_table(instruction, steps):
    """Ù†Ù…Ø§ÛŒØ´ Ø¬Ø¯ÙˆÙ„ Ø±Ø¯ÛŒØ§Ø¨ÛŒ Shift-Reduce (Ø¨Ø±Ø§ÛŒ Ù…Ø«Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ø§Ø³ØªØ§ØªÛŒÚ©)"""
    print(f"\nğŸ“‹ Ø¯Ø³ØªÙˆØ± ÙˆØ±ÙˆØ¯ÛŒ: {instruction}")
    print("\n" + "â”€" * 100)

    header = f"{'Ù…Ø±Ø­Ù„Ù‡':<8} | {'Ù¾Ø´ØªÙ‡ (Stack)':<30} | {'ÙˆØ±ÙˆØ¯ÛŒ Ø¨Ø§Ù‚ÛŒâ€ŒÙ…Ø§Ù†Ø¯Ù‡':<25} | {'Ø¹Ù…Ù„ÛŒØ§Øª':<15} | {'Ù‚Ø§Ù†ÙˆÙ†/ØªÙˆØ¶ÛŒØ­':<20}"
    print(header)
    print("â”€" * 100)

    for step in steps:
        step_num = step['step']
        stack = step['stack']
        input_remaining = step['input']
        action = step['action']
        rule = step['rule']
        print(f"{step_num:<8} | {stack:<30} | {input_remaining:<25} | {action:<15} | {rule:<20}")

    print("â”€" * 100)
    print("âœ… Ù¾Ø§Ø±Ø³ Ù…ÙˆÙÙ‚ - Ø¯Ø³ØªÙˆØ± Ù…Ø¹ØªØ¨Ø± Ø§Ø³Øª\n")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ù…Ø«Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ø§Ø² Ù¾ÛŒØ´ ØªØ¹Ø±ÛŒÙ Ø´Ø¯Ù‡ (Ø¨Ø±Ø§ÛŒ ØªØ³Øª Ùˆ Ø¢Ù…ÙˆØ²Ø´)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def example1_simple():
    """Ù…Ø«Ø§Ù„ 1: CLFLUSH [EAX]"""
    print_header("Ù…Ø«Ø§Ù„ 1: CLFLUSH [EAX] - Ø¯Ø³ØªÙˆØ± Ø³Ø§Ø¯Ù‡")

    steps = [
        {'step': 1, 'stack': '$', 'input': 'CLFLUSH [ EAX ] $',
         'action': 'Shift', 'rule': 'Ø§Ù†ØªÙ‚Ø§Ù„ CLFLUSH'},
        {'step': 2, 'stack': '$ CLFLUSH', 'input': '[ EAX ] $',
         'action': 'Reduce', 'rule': 'R3: mnemonic â†’ CLFLUSH'},
        {'step': 3, 'stack': '$ mnemonic', 'input': '[ EAX ] $',
         'action': 'Shift', 'rule': 'Ø§Ù†ØªÙ‚Ø§Ù„ ['},
        {'step': 4, 'stack': '$ mnemonic [', 'input': 'EAX ] $',
         'action': 'Shift', 'rule': 'Ø§Ù†ØªÙ‚Ø§Ù„ Ø±Ø¬ÛŒØ³ØªØ±'},
        {'step': 5, 'stack': '$ mnemonic [ EAX', 'input': '] $',
         'action': 'Reduce', 'rule': 'R15: base_expr â†’ REGISTER'},
        {'step': 6, 'stack': '$ mnemonic [ base_expr', 'input': '] $',
         'action': 'Shift', 'rule': 'Ø§Ù†ØªÙ‚Ø§Ù„ ]'},
        {'step': 7, 'stack': '$ mnemonic [ base_expr ]', 'input': '$',
         'action': 'Reduce', 'rule': 'R13: memory_address â†’ [base_expr]'},
        {'step': 8, 'stack': '$ mnemonic operand', 'input': '$',
         'action': 'Reduce', 'rule': 'R1: instruction â†’ mnemonic operand'},
        {'step': 9, 'stack': '$ instruction', 'input': '$',
         'action': 'Accept', 'rule': 'âœ… Ù¾Ø°ÛŒØ±Ø´'}
    ]

    print_trace_table("CLFLUSH [EAX]", steps)


def example2_no_operand():
    """Ù…Ø«Ø§Ù„ 2: WBINVD"""
    print_header("Ù…Ø«Ø§Ù„ 2: WBINVD - Ø¯Ø³ØªÙˆØ± Ø¨Ø¯ÙˆÙ† Operand")

    steps = [
        {'step': 1, 'stack': '$', 'input': 'WBINVD $',
         'action': 'Shift', 'rule': 'Ø§Ù†ØªÙ‚Ø§Ù„ WBINVD'},
        {'step': 2, 'stack': '$ WBINVD', 'input': '$',
         'action': 'Reduce', 'rule': 'R10: mnemonic â†’ WBINVD'},
        {'step': 3, 'stack': '$ mnemonic', 'input': '$',
         'action': 'Reduce', 'rule': 'R2: instruction â†’ mnemonic'},
        {'step': 4, 'stack': '$ instruction', 'input': '$',
         'action': 'Accept', 'rule': 'âœ… Ù¾Ø°ÛŒØ±Ø´'}
    ]

    print_trace_table("WBINVD", steps)


def example3_with_offset():
    """Ù…Ø«Ø§Ù„ 3: CLFLUSHOPT [EBX+16]"""
    print_header("Ù…Ø«Ø§Ù„ 3: CLFLUSHOPT [EBX+16] - Ø¯Ø³ØªÙˆØ± Ø¨Ø§ Offset")

    steps = [
        {'step': 1, 'stack': '$', 'input': 'CLFLUSHOPT [ EBX + 16 ] $',
         'action': 'Shift', 'rule': 'Ø§Ù†ØªÙ‚Ø§Ù„ CLFLUSHOPT'},
        {'step': 2, 'stack': '$ CLFLUSHOPT', 'input': '[ EBX + 16 ] $',
         'action': 'Reduce', 'rule': 'R4: mnemonic â†’ CLFLUSHOPT'},
        {'step': 3, 'stack': '$ mnemonic', 'input': '[ EBX + 16 ] $',
         'action': 'Shift', 'rule': 'Ø§Ù†ØªÙ‚Ø§Ù„ ['},
        {'step': 4, 'stack': '$ mnemonic [', 'input': 'EBX + 16 ] $',
         'action': 'Shift', 'rule': 'Ø§Ù†ØªÙ‚Ø§Ù„ Ø±Ø¬ÛŒØ³ØªØ±'},
        {'step': 5, 'stack': '$ mnemonic [ EBX', 'input': '+ 16 ] $',
         'action': 'Shift', 'rule': 'Ø§Ù†ØªÙ‚Ø§Ù„ +'},
        {'step': 6, 'stack': '$ mnemonic [ EBX +', 'input': '16 ] $',
         'action': 'Shift', 'rule': 'Ø§Ù†ØªÙ‚Ø§Ù„ Ø¹Ø¯Ø¯'},
        {'step': 7, 'stack': '$ mnemonic [ EBX + 16', 'input': '] $',
         'action': 'Reduce', 'rule': 'R17: offset â†’ + NUMBER'},
        {'step': 8, 'stack': '$ mnemonic [ EBX offset', 'input': '] $',
         'action': 'Reduce', 'rule': 'R14: base_expr â†’ REGISTER offset'},
        {'step': 9, 'stack': '$ mnemonic [ base_expr', 'input': '] $',
         'action': 'Shift', 'rule': 'Ø§Ù†ØªÙ‚Ø§Ù„ ]'},
        {'step': 10, 'stack': '$ mnemonic [ base_expr ]', 'input': '$',
         'action': 'Reduce', 'rule': 'R13: memory_address â†’ [base_expr]'},
        {'step': 11, 'stack': '$ mnemonic operand', 'input': '$',
         'action': 'Reduce', 'rule': 'R1: instruction â†’ mnemonic operand'},
        {'step': 12, 'stack': '$ instruction', 'input': '$',
         'action': 'Accept', 'rule': 'âœ… Ù¾Ø°ÛŒØ±Ø´'}
    ]

    print_trace_table("CLFLUSHOPT [EBX+16]", steps)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Main (Ø¨Ø±Ø§ÛŒ ØªØ³Øª Ù…Ø³ØªÙ‚Ù„)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def main():
    """ØªØ§Ø¨Ø¹ Ø§ØµÙ„ÛŒ Ø¨Ø±Ø§ÛŒ Ø§Ø¬Ø±Ø§ÛŒ Ù…Ø³ØªÙ‚Ù„"""
    print("\n" + "â•”" + "â•" * 98 + "â•—")
    print("â•‘" + " " * 30 + "ØªØ­Ù„ÛŒÙ„ Ø¯Ø³ØªÛŒ Shift-Reduce Parse" + " " * 38 + "â•‘")
    print("â•‘" + " " * 35 + "Ù¾Ø±ÙˆÚ˜Ù‡ Ú©Ø§Ù…Ù¾Ø§ÛŒÙ„Ø± - Ú¯Ø±ÙˆÙ‡ 15" + " " * 39 + "â•‘")
    print("â•‘" + " " * 28 + "Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡ Ø´Ù‡ÛŒØ¯ Ø¨Ø§Ù‡Ù†Ø± Ú©Ø±Ù…Ø§Ù† - Ø²Ù…Ø³ØªØ§Ù† Û±Û´Û°Û´" + " " * 30 + "â•‘")
    print("â•š" + "â•" * 98 + "â•")

    # Ù…Ø«Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ø§Ø³ØªØ§ØªÛŒÚ©
    example1_simple()
    example2_no_operand()
    example3_with_offset()

    # ØªØ³Øª Ø¯ÛŒÙ†Ø§Ù…ÛŒÚ©
    print_header("ØªØ³Øª Ø¯ÛŒÙ†Ø§Ù…ÛŒÚ© Ø¨Ø§ Lexer Ùˆ Ø¬Ø¯ÙˆÙ„ LR(0)")

    test_instructions = [
        "WBINVD",
        "CLFLUSH [EAX]",
        "CLFLUSHOPT [EBX+16]",
        "CLWB [RCX-8]"
    ]

    for instruction in test_instructions:
        trace_shift_reduce(instruction)

    # Ù†ØªÛŒØ¬Ù‡â€ŒÚ¯ÛŒØ±ÛŒ
    print("â•" * 100)
    print("ğŸ“Š Ø®Ù„Ø§ØµÙ‡ ØªØ­Ù„ÛŒÙ„")
    print("â•" * 100)
    print("""
âœ… ØªØ¹Ø¯Ø§Ø¯ Ù…Ø«Ø§Ù„â€ŒÙ‡Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ø´Ø¯Ù‡: 7
âœ… Ø§Ù†ÙˆØ§Ø¹ Ø¯Ø³ØªÙˆØ±Ø§Øª: Flush, WriteBack, Prefetch, Invalidate
âœ… Ø§Ù†ÙˆØ§Ø¹ Ø¹Ù…Ù„ÙˆÙ†Ø¯: Ø±Ø¬ÛŒØ³ØªØ± Ø³Ø§Ø¯Ù‡ØŒ Ø¨Ø§ offset Ù…Ø«Ø¨ØªØŒ Ø¨Ø§ offset Ù…Ù†ÙÛŒØŒ Ø¨Ø¯ÙˆÙ† Ø¹Ù…Ù„ÙˆÙ†Ø¯
âœ… Ù†ØªÛŒØ¬Ù‡: Ù‡Ù…Ù‡ Ø¯Ø³ØªÙˆØ±Ø§Øª Ù…Ø¹ØªØ¨Ø± Ùˆ Ù‚Ø§Ø¨Ù„ Ù¾Ø§Ø±Ø³ Ù‡Ø³ØªÙ†Ø¯

Ø§ÛŒÙ† ØªØ­Ù„ÛŒÙ„ Ù†Ø´Ø§Ù† Ù…ÛŒâ€ŒØ¯Ù‡Ø¯ Ú¯Ø±Ø§Ù…Ø± Ø·Ø±Ø§Ø­ÛŒ Ø´Ø¯Ù‡:
  â€¢ Ø¨Ø¯ÙˆÙ† Ø§Ø¨Ù‡Ø§Ù… Ø§Ø³Øª
  â€¢ Ù‚Ø§Ø¨Ù„ Ù¾Ø§Ø±Ø³ Ø¨Ù‡ Ø±ÙˆØ´ LR(0) Ø§Ø³Øª
  â€¢ ØªÙ…Ø§Ù… Ø­Ø§Ù„Ø§Øª Ù…Ù…Ú©Ù† Ø±Ø§ Ù¾ÙˆØ´Ø´ Ù…ÛŒâ€ŒØ¯Ù‡Ø¯
  â€¢ Ø¨Ø§ Ø¬Ø¯ÙˆÙ„ LR ØªØµØ­ÛŒØ­ Ø´Ø¯Ù‡ Ú©Ø§Ø± Ù…ÛŒâ€ŒÚ©Ù†Ø¯ âœ…
  â€¢ Ø¨Ø§ Lexer Ø³Ø§Ø²Ú¯Ø§Ø± Ø§Ø³Øª âœ…
""")
    print("â•" * 100 + "\n")


if __name__ == "__main__":
    main()
